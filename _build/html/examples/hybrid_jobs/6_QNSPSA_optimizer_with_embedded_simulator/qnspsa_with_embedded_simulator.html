<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 5.3.0 and Furo 2022.12.07 -->
        <title>Benchmarking QN-SPSA optimizer with Amazon Braket Hybrid Jobs and embedded simulators - Amazon Braket Examples documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Amazon Braket Examples  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">Amazon Braket Examples  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  
</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="benchmarking-qn-spsa-optimizer-with-amazon-braket-hybrid-jobs-and-embedded-simulators">
<h1>Benchmarking QN-SPSA optimizer with Amazon Braket Hybrid Jobs and embedded simulators<a class="headerlink" href="#benchmarking-qn-spsa-optimizer-with-amazon-braket-hybrid-jobs-and-embedded-simulators" title="Permalink to this heading">#</a></h1>
<p>This notebook demonstrates how to implement and benchmark the QN-SPSA optimizer, a novel quantum optimization algorithm proposed by Gacon et al. [1]. Following this example, we will show how you can use Amazon Braket Hybrid Jobs to iterate faster on variational algorithm research, discuss best practices, and help you scale up your simulations with embedded simulators.</p>
<section id="introduction-on-hybrid-jobs-and-embedded-simulators">
<h2>Introduction on Hybrid Jobs and embedded simulators<a class="headerlink" href="#introduction-on-hybrid-jobs-and-embedded-simulators" title="Permalink to this heading">#</a></h2>
<p>Amazon Braket Hybrid Jobs simplifies the process of setting up, monitoring, and efficiently executing hybrid quantum-classical algorithms and it helps you conduct systematic and reproducible quantum experiments on Amazon Braket. Hybrid Jobs are fully managed, which means you only need to provide your algorithm as a script, select the quantum device you want to run on, and then submit your job. Amazon Braket will spin up the requested classical compute (i.e., the job instance) to run your algorithm script, and manage the execution of quantum tasks on the selected device. You can select all QPUs and on-demand simulators (i.e. <a class="reference external" href="https://us-east-1.console.aws.amazon.com/braket/home?region=us-east-1#/devices/arn:aws:braket:::device/quantum-simulator/amazon/sv1">SV1</a>, <a class="reference external" href="https://us-east-1.console.aws.amazon.com/braket/home?region=us-east-1#/devices/arn:aws:braket:::device/quantum-simulator/amazon/dm1">DM1</a>, and <a class="reference external" href="https://us-east-1.console.aws.amazon.com/braket/home?region=us-east-1#/devices/arn:aws:braket:::device/quantum-simulator/amazon/tn1">TN1</a>) as the target device of your algorithm, or run simulations directly on the job instance using <em>embedded simulators</em>, such as, PennyLane’s <code class="docutils literal notranslate"><span class="pre">lighting.qubit</span></code> and <code class="docutils literal notranslate"><span class="pre">lighting.gpu</span></code>.  Embedded simulators benefit from lower latency compared to on-demand simulators, whereas on-demand simulators allow you to run many tasks in parallel.</p>
<p>You can learn more about embedded simulators in <a class="reference external" href="https://github.com/aws/amazon-braket-examples/blob/main/examples/hybrid_jobs/4_Embedded_simulators_in_Braket_Jobs/Embedded_simulators_in_Braket_Jobs.ipynb">this example notebook</a>.</p>
</section>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this heading">#</a></h2>
<section id="variational-quantum-algorithms">
<h3>Variational quantum algorithms<a class="headerlink" href="#variational-quantum-algorithms" title="Permalink to this heading">#</a></h3>
<p>Variational quantum algorithms (VQAs) are promising approaches in the noisy intermediate-scale quantum (NISQ) era, as they utilize classical computational resources to iteratively find solutions to the problem at hand and usually require only relatively shallow circuits to execute on the QPU. In VQA, you encode the quantity of interest as the ground state energy of a problem Hamiltonian. The algorithm can be then considered as a close-loop optimization process, where the loss function is defined by the expectation value of the Hamiltonian, while the circuit ansatz is parameterized with a set of classical parameters. With gradients (and possibly other metrics) measured from the quantum devices, an optimizer, such as gradient descent, is used to find the best parameters minimizing the loss.</p>
</section>
<section id="qn-spsa-optimizer">
<h3>QN-SPSA optimizer<a class="headerlink" href="#qn-spsa-optimizer" title="Permalink to this heading">#</a></h3>
<p>The update rule of a vanilla gradient descent (GD) is written as:</p>
<p>\begin{equation}
x^{(t + 1)} = x^{(t)} - \eta \nabla f(x^{(t)}) \label{eq:vanilla}\tag{1}.
\end{equation}</p>
<p>For quantum circuits, the gradient $\nabla f(x^{(t)})$ is then estimated dimension by dimension, requiring $O(d)$ quantum measurements ($d$ being the dimension of the parameter space). As quantum measurements are expensive, this scaling makes GD impractical when dealing with high-dimensional complicated circuits.</p>
<p>SPSA replaces this dimension-wise gradient estimation with a stochastic one [2]. In SPSA, a randomly sampled direction is used to provide a finite-difference approximation on the gradient. Although this stochastic approach cannot provide a step-wise unbiased gradient estimation, SPSA is proved to be especially effective when accumulated over multiple optimization steps.</p>
<p>On the other hand, quantum natural gradient descent (QNG) is a variant of gradient descent. It introduces the Fubini-Study metric tensor $g$ [4] into the optimization to account for the structure of the non-Euclidean parameter space [5]. The $d$-by-$d$ metric tensor is defined as</p>
<p>$$
g_{ij} = -\frac{1}{2} \frac{\partial}{\partial x_i} \frac{\partial}{\partial x_j} \bigr\rvert\langle \phi(x’) | \phi(x) \rangle \bigr\rvert ^ 2\biggr\rvert_{x’=x},\label{eq:fs_tensor}\tag{2}
$$</p>
<p>where $\phi(x)$ is the parameterized ansatz with parameters $x$. With the metric tensor, the update rule is rewritten as:</p>
<p>\begin{align}
x^{(t + 1)} = x^{(t)} - \eta g^{-1}\nabla f(x^{(t)}) \label{eq:qn}\tag{3}.
\end{align}</p>
<p>While the introduction of the metric tensor helps the optimization [3], the algorithm is not as scalable due to the number of measurements required to estimate $g$.</p>
<p>In a hand-waving argument, quantum natural simultaneous perturbation stochastic approximation (QN-SPSA, proposed by Gacon et al. [1]) is a second-order SPSA algorithm. QN-SPSA combines the merits of both QNG and SPSA by generalizing SPSA to second order and estimating both the gradient and the metric tensor stochastically. The gradient is estimated in the same fashion as the SPSA algorithm, while the Fubini-Study metric is computed by a second-order process with another two pairs of stochastic perturbations. QN-SPSA then executes a constant number of circuits per optimization step (2 for the gradient, 4 for the metric tensor). This $O(1)$ update rule is well suited for NISQ devices.</p>
<p>Let’s take a look how QN-SPSA can be implemented with PennyLane and Braket.</p>
</section>
</section>
<section id="notebook-dependencies">
<h2>Notebook dependencies<a class="headerlink" href="#notebook-dependencies" title="Permalink to this heading">#</a></h2>
<div class="alert alert-block alert-info">
<b>Note:</b> This notebook requires the following packages to execute. It is confirmed to work with: 
   <ul>
    <li>Pennylane version <b>0.22.0</b> (or later)</li>
    <li>Braket SDK version <b>1.20.0</b> (or later)</li>
</ul>   
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import dependencies</span>
<span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">qaoa</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">braket._sdk</span> <span class="k">as</span> <span class="nn">braket_sdk</span>
<span class="kn">from</span> <span class="nn">braket.jobs.image_uris</span> <span class="kn">import</span> <span class="n">Framework</span><span class="p">,</span> <span class="n">retrieve_image</span>
<span class="kn">from</span> <span class="nn">braket.jobs.local.local_job</span> <span class="kn">import</span> <span class="n">LocalQuantumJob</span>
<span class="kn">from</span> <span class="nn">braket.aws</span> <span class="kn">import</span> <span class="n">AwsQuantumTask</span><span class="p">,</span> <span class="n">AwsSession</span><span class="p">,</span> <span class="n">AwsQuantumJob</span>
<span class="kn">from</span> <span class="nn">braket.jobs.config</span> <span class="kn">import</span> <span class="n">InstanceConfig</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">boto3</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># check package versions</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current pennylane version&quot;</span><span class="p">,</span> <span class="n">qml</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current braket sdk version&quot;</span><span class="p">,</span> <span class="n">braket_sdk</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Current pennylane version 0.22.0
Current braket sdk version 1.20.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="implementation-and-notebook-test">
<h2>Implementation and notebook test<a class="headerlink" href="#implementation-and-notebook-test" title="Permalink to this heading">#</a></h2>
<p>Let’s start with implementing a prototype QN-SPSA algorithm using PennyLane in a Braket notebook. Notebooks are a convenient tool for first exploration and prototyping. They come preinstalled with the necessary packages, saving time to set up the environment on, say, your laptop. A notebook instance of <code class="docutils literal notranslate"><span class="pre">ml.t3.medium</span></code> is sufficient to test and debug on a small scale, and it costs (at the writing of this example) 5 cents per hour. You can find more information on Braket pricing <a class="reference external" href="https://aws.amazon.com/braket/pricing/">here</a>.</p>
<p>We have included the optimizer class in <code class="docutils literal notranslate"><span class="pre">source_scripts/QNSPSA.py</span></code>. It follows PennyLane’s convention for <a class="reference external" href="https://pennylane.readthedocs.io/en/stable/introduction/optimizers.html">optimizers</a>, with two class methods exposed to the users:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">opt.step(loss_fn,</span> <span class="pre">parameters)</span></code> returns the updated parameters after one step of QN-SPSA optimization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">opt.step_and_cost(loss_fn,</span> <span class="pre">parameters)</span></code> returns the updated parameter after one step, along with the loss value before the update.</p></li>
</ul>
<p>The optimizer’s core process can be found in the <code class="docutils literal notranslate"><span class="pre">__step_core()</span></code> function. The functions <code class="docutils literal notranslate"><span class="pre">__get_spsa_grad_tapes()</span></code> and <code class="docutils literal notranslate"><span class="pre">__get_tensor_tapes()</span></code> schedule the circuits to be executed for the stochastic gradient estimation and tensor metric estimation, and <code class="docutils literal notranslate"><span class="pre">qml.execute()</span></code> sends them to the simulator device.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>sed -n <span class="m">110</span>,123p source_scripts/QNSPSA.py
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    def __step_core(self, cost, params):
        grad_avg = np.zeros(params.shape)
        tensor_avg = np.zeros((params.size, params.size))
        for i in range(self.resamplings):
            grad_tapes, grad_dir = self.__get_spsa_grad_tapes(cost, params)
            metric_tapes, tensor_dirs = self.__get_tensor_tapes(cost, params)
            raw_results = qml.execute(grad_tapes + metric_tapes, cost.device, None)
            grad = self.__post_process_grad(raw_results[:2], grad_dir)
            metric_tensor = self.__post_process_tensor(raw_results[2:], tensor_dirs)
            grad_avg = grad_avg * i / (i + 1) + grad / (i + 1)
            tensor_avg = tensor_avg * i / (i + 1) + metric_tensor / (i + 1)

        self.__update_tensor(tensor_avg)
        return self.__get_next_params(params, grad_avg)
</pre></div>
</div>
</div>
</div>
<p>To confirm the optimizer works correctly, let’s work with a toy QAOA maximum cut example [6]. The maximum cut problem is to partition the nodes of a graph into two subsets such that the number of edges going between the subsets is maximized. The QAOA max cut problem can be conveniently set up with the <a class="reference external" href="https://pennylane.readthedocs.io/en/stable/code/api/pennylane.qaoa.cost.maxcut.html">PennyLane’s QAOA module</a>. You can find a more detailed and visualized example <a class="reference external" href="https://github.com/aws/amazon-braket-examples/blob/17ba255396f4c2bf773dde99a5c46486e822776e/examples/hybrid_jobs/2_Using_PennyLane_with_Braket_Jobs/Using_PennyLane_with_Braket_Jobs.ipynb">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># QAOA max cut problem set up.</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">edges</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">gnm_random_graph</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">cost_h</span><span class="p">,</span> <span class="n">mixer_h</span> <span class="o">=</span> <span class="n">qaoa</span><span class="o">.</span><span class="n">maxcut</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

<span class="c1"># Defining device to be the pennylane lightning local simulator</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;lightning.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">n_qubits</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">qaoa_layer</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">qaoa</span><span class="o">.</span><span class="n">cost_layer</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">cost_h</span><span class="p">)</span>
    <span class="n">qaoa</span><span class="o">.</span><span class="n">mixer_layer</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">mixer_h</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">qaoa_circuit</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
    <span class="c1">#initalizing all qubits into +X eigenstate. </span>
    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">):</span>
        <span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
    <span class="n">gammas</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">alphas</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1">#stacking building blocks for depth times.</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">layer</span><span class="p">(</span><span class="n">qaoa_layer</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">gammas</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
    
<span class="c1"># Defining ansatz and cost function</span>
<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">qaoa_circuit</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">cost_h</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>In QAOA, the loss is given by the expectation value of the cost Hamiltonian. The negation of the loss represents the number of edges between the two subsets, while the two subsets are specified by the $Z$ values of each qubit (node). Nodes with the same $Z$ value are of the same subset. Finding the maximum cut is then equivalent to finding the mininum-energy state of the cost Hamiltonian, which is done variationally in the QAOA algorithm. The basic building block of the QAOA ansatz is a cost layer followed with a mixer layer. This building block repeats for $p$ times resulting in the final ansatz circuit. A larger $p$ value leads generally to better approximations of the solution in the ideal case, however, the noise on real QPUs will prevent you from going to higher values since the circuits get deeper with increasing $p$. In practice, a lot of experimentation is required to find the best values for your problem and device choice.</p>
<p>Now let’s take a look if our optimizer indeed reduces the loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import the QN-SPSA optimizer</span>
<span class="kn">from</span> <span class="nn">source_scripts.QNSPSA</span> <span class="kn">import</span> <span class="n">QNSPSA</span>
<span class="c1"># Optimize with QN-SPSA</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">QNSPSA</span><span class="p">(</span><span class="n">stepsize</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">)</span>
<span class="n">params_init</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">params_init</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">params</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">step_and_cost</span><span class="p">(</span><span class="n">cost_function</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: cost = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Step 0: cost = -1.6159
Step 10: cost = -2.0127
Step 20: cost = -2.0191
Step 30: cost = -2.4048
Step 40: cost = -2.7166
Step 50: cost = -2.7435
Step 60: cost = -2.7589
Step 70: cost = -2.7612
Step 80: cost = -2.7770
Step 90: cost = -2.7909
</pre></div>
</div>
</div>
</div>
<p>As the loss drops and finally converges, we can tell that the optimizer works!</p>
</section>
<section id="comparing-qn-spsa-with-other-optimizers">
<h2>Comparing QN-SPSA with other optimizers<a class="headerlink" href="#comparing-qn-spsa-with-other-optimizers" title="Permalink to this heading">#</a></h2>
<p>Next, let us compare the performance of the QN-SPSA optimizer with other approaches, SPSA, vanilla gradient descent and quantum natural gradient descent.  This experiment follows the benchmarking performed in Ref. [1]. You can find more information on the definition of the problem Hamiltonian and additional details of the selected ansatz in Ref. [1].</p>
<p>In this section we will use Hybrid Jobs with embedded simulators to demonstrate the benefits Hybrid Jobs provides for experimentation and research:</p>
<ul class="simple">
<li><p>First, Hybrid Jobs helps you create reproducible experiments. It enables you to systematically track experiments, logs, and the corresponding results.</p></li>
<li><p>Second, some of the algorithms we will run will take a while to complete. Instead of having to keep your notebook or laptop running for the duration of the algorithm, Hybrid Jobs, allows you to ‘set and forget’ you experiment. The job runs your algorithm until completion and automatically shuts down your compute resources at completion, so you only pay for the time and resources you actually use. This can be particularly important for larger test with more qubits, where we want to use more powerful instances to accelerate the execution of our jobs.</p></li>
<li><p>Third, since we run and compare several different approaches, we can accelerate our experimentation cycle by executing different runs in parallel. With Hybrid Jobs, we can kick off multiple jobs at the same time. Each job will spin up the requested resources and execute the algorithm independently. Once all jobs are completed, we can collect and analyze the results.</p></li>
</ul>
<p>We have prepared an an algorithm script,  <code class="docutils literal notranslate"><span class="pre">source_scripts/benchmark_ref_paper_converge_speed</span></code>, which reproduces the experiment in Fig 1(b) from Ref. [1] with the selected optimizer from the four candidates (GD, QNG, QNSPSA, SPSA). First, let’s test if the script works as expected. Hybrid Jobs provides a <a class="reference external" href="https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs-local-mode.html">local mode</a> for testing and debugging. It enables you to quickly test your code in your local environment, e.g. a Braket notebook, before running it remotely on a job instance. Let’s start by selecting the Braket base container which comes pre-installed with PennyLane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve one of the default images (environment), with pennylane pre-installed</span>
<span class="n">region_name</span> <span class="o">=</span> <span class="n">AwsSession</span><span class="p">()</span><span class="o">.</span><span class="n">region</span>
<span class="n">image_uri</span> <span class="o">=</span> <span class="n">retrieve_image</span><span class="p">(</span><span class="n">Framework</span><span class="o">.</span><span class="n">BASE</span><span class="p">,</span> <span class="n">region_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">image_uri</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>292282985366.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-base-jobs:1.0-cpu-py37-ubuntu18.04
</pre></div>
</div>
</div>
</div>
<p>We can then start a local job using the code below. We first set the hyperparameters, give our job a name, and then create it using the <code class="docutils literal notranslate"><span class="pre">LocalQuantumJob</span></code> API. Since QN-SPSA is a stochastic method, we repeat the algorithm <code class="docutils literal notranslate"><span class="pre">spsa_repeats</span></code> times to capture the average performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="c1"># This cell should take about 2 min for the first time, </span>
<span class="c1"># and about 30 seconds afterward.</span>

<span class="n">hyperparameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_qubits&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;shots&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="mi">60</span><span class="p">,</span>
    <span class="s2">&quot;learn_rate&quot;</span><span class="p">:</span> <span class="mf">1e-2</span><span class="p">,</span>
    <span class="s2">&quot;spsa_repeats&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="c1"># seed is used to initialize parameters, and to randomly sample </span>
    <span class="c1"># the the gate sequence for the ansatz,</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="s2">&quot;QNSPSA&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="n">hyperparameters</span><span class="p">[</span><span class="s2">&quot;max_iter&quot;</span><span class="p">]</span>

<span class="n">job_name</span> <span class="o">=</span> <span class="s2">&quot;local-embedded-simulation-&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()))</span>

<span class="n">job</span> <span class="o">=</span> <span class="n">LocalQuantumJob</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;local:pennylane/lightning.qubit&quot;</span><span class="p">,</span>
    <span class="n">source_module</span><span class="o">=</span><span class="s2">&quot;source_scripts&quot;</span><span class="p">,</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;source_scripts.benchmark_ref_paper_converge_speed&quot;</span><span class="p">,</span>
    <span class="n">job_name</span><span class="o">=</span><span class="n">job_name</span><span class="p">,</span>
    <span class="n">hyperparameters</span><span class="o">=</span><span class="n">hyperparameters</span><span class="p">,</span>
    <span class="n">image_uri</span><span class="o">=</span><span class="n">image_uri</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:braket.jobs.local.local_job_container_setup:Using the short-lived AWS credentials found in session. They might expire while running.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Boto3 Version:  1.22.7
Beginning Setup
Running Code As Subprocess
{&#39;n_qubits&#39;: &#39;4&#39;, &#39;n_layers&#39;: &#39;2&#39;, &#39;shots&#39;: &#39;1000&#39;, &#39;max_iter&#39;: &#39;60&#39;, &#39;learn_rate&#39;: &#39;0.01&#39;, &#39;spsa_repeats&#39;: &#39;2&#39;, &#39;seed&#39;: &#39;1&#39;, &#39;optimizer&#39;: &#39;QNSPSA&#39;}
Using local simulator:  Lightning Qubit PennyLane plugin
QNSPSA optimizer:
Trace 0:
Step 0:  loss = 0.32
Step 20:  loss = 0.05
Step 40:  loss = -0.26
Trace 1:
Step 0:  loss = 0.34
Step 20:  loss = -0.28
Step 40:  loss = -0.44
Training Successful!!
Code Run Finished
CPU times: user 194 ms, sys: 124 ms, total: 318 ms
Wall time: 29.2 s
</pre></div>
</div>
</div>
</div>
<p>Note that each local Job will create a folder under the current path storing the log and result so you can understand the details of the test if needed.</p>
<p>Now that we have confirmed the code works correctly, we can reproduce the full benchmark of Ref [1]. In the following cell, we will create a set of jobs, one for each optimizer. The four jobs will start and execute in parallel, allowing us to speed up the experiment. For now, we will use a relatively small instance type, <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code>, which has 2 vCPUs and 8 GiB of memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The execution time of the 4 jobs is about 50 min, and charges about $0.1.</span>
<span class="c1"># Feel free to uncomment the cell to run.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">n_qubits = 11</span>
<span class="sd">optimizers = [&quot;GD&quot;, &quot;QNG&quot;, &quot;QNSPSA&quot;, &quot;SPSA&quot;]</span>
<span class="sd">repeats = [1, 1, 25, 25]</span>

<span class="sd">hyperparameters = {</span>
<span class="sd">    &quot;n_qubits&quot;: n_qubits,</span>
<span class="sd">    &quot;n_layers&quot;: 4,</span>
<span class="sd">    &quot;shots&quot;: 8192,</span>
<span class="sd">    &quot;max_iter&quot;: 600,</span>
<span class="sd">    &quot;learn_rate&quot;: 1e-2,</span>
<span class="sd">    &quot;seed&quot;: 121,</span>
<span class="sd">}</span>

<span class="sd">max_iter = hyperparameters[&quot;max_iter&quot;]</span>

<span class="sd">jobs = []</span>
<span class="sd">for i in range(len(optimizers)):</span>
<span class="sd">    hyperparameters[&quot;spsa_repeats&quot;] = repeats[i]</span>
<span class="sd">    hyperparameters[&quot;optimizer&quot;] = optimizers[i]</span>
<span class="sd">    job_name = f&quot;ref-paper-benchmark-qubit{n_qubits}-opt{optimizers[i]}&quot; + str(int(time.time()))</span>
<span class="sd">    instance_config = InstanceConfig(instanceType=&#39;ml.m5.large&#39;, volumeSizeInGb=30, instanceCount=1)</span>

<span class="sd">    job = AwsQuantumJob.create(</span>
<span class="sd">        device=&quot;local:pennylane/lightning.qubit&quot;,</span>
<span class="sd">        source_module=&quot;source_scripts&quot;,</span>
<span class="sd">        entry_point=&quot;source_scripts.benchmark_ref_paper_converge_speed&quot;,</span>
<span class="sd">        job_name=job_name,</span>
<span class="sd">        hyperparameters=hyperparameters,</span>
<span class="sd">        instance_config=instance_config,</span>
<span class="sd">        image_uri=image_uri,</span>
<span class="sd">        wait_until_complete=False,</span>
<span class="sd">    )</span>
<span class="sd">    jobs.append(job)</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>After you create your job it will asynchronously run on Braket and not block your notebook. You can continue to work in your notebook while the job is executing and check back on the results after the job has completed.</p>
<p>Each remote job has a unique identifier, referred as the Job ARN. You can always retrieve the ARN of your Hybrid Jobs from the <em>Jobs</em> tab of the Amazon Braket console. It is also recommended to keep a copy of the Job ARN to pull the result at a later time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">job_arns</span> <span class="o">=</span> <span class="p">[</span><span class="n">job</span><span class="o">.</span><span class="n">arn</span> <span class="k">for</span> <span class="n">job</span> <span class="ow">in</span> <span class="n">jobs</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">job_arns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;arn:aws:braket:us-east-1:&lt;aws_id&gt;:job/ref-paper-benchmark-qubit11-optGD1654882190&#39;, &#39;arn:aws:braket:us-east-1:&lt;aws_id&gt;:job/ref-paper-benchmark-qubit11-optQNG1654882193&#39;, &#39;arn:aws:braket:us-east-1:&lt;aws_id&gt;:job/ref-paper-benchmark-qubit11-optQNSPSA1654882196&#39;, &#39;arn:aws:braket:us-east-1:&lt;aws_id&gt;:job/ref-paper-benchmark-qubit11-optSPSA1654882200&#39;]
</pre></div>
</div>
</div>
</div>
<p>It takes about 50 min for the longest of the four jobs to finish. As of writing of this example the cost of an <code class="docutils literal notranslate"><span class="pre">ml.m5.large</span></code> instance is $$0.115$ per hour, so that the estimated cost of running this cell is well below $$1$.</p>
<p>Once all jobs have completed you can retrieve the results with the following line of code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">AwsQuantumJob</span><span class="p">(</span><span class="n">job_arn</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">job_arn</span> <span class="ow">in</span> <span class="n">job_arns</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We can now process the result and visualize the performance of each optimizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">step</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
<span class="n">loss_gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;GD_loss_per_iter&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">loss_qng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;QNG_loss_per_iter&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">qnspsa_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;QNSPSA_loss_per_iter&#39;</span><span class="p">])</span>
<span class="n">qnspsa_loss_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">qnspsa_loss_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">qnspsa_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">spsa_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;SPSA_loss_per_iter&#39;</span><span class="p">])</span>
<span class="n">spsa_loss_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spsa_loss_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spsa_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ground_energy</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">step</span><span class="p">,</span> <span class="n">loss_gd</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">,</span> <span class="n">loss_qng</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">,</span> <span class="n">qnspsa_loss_mean</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span>
    <span class="n">step</span><span class="p">,</span> <span class="n">spsa_loss_mean</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">ground_energy</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">qnspsa_loss_min</span><span class="p">,</span> <span class="n">qnspsa_loss_max</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">spsa_loss_min</span><span class="p">,</span> <span class="n">spsa_loss_max</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;GD&#39;</span><span class="p">,</span> <span class="s1">&#39;QNG&#39;</span><span class="p">,</span> <span class="s1">&#39;QN-SPSA&#39;</span><span class="p">,</span> <span class="s1">&#39;SPSA&#39;</span><span class="p">,</span> <span class="s1">&#39;ground energy&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Step&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/ae2b8b51ea11c3c2dc0376f01c027175b8f3cc3532e424149f0bbdb6a20856f0.png" src="../../../_images/ae2b8b51ea11c3c2dc0376f01c027175b8f3cc3532e424149f0bbdb6a20856f0.png" />
</div>
</div>
<p>The above plot shows how the loss drops over optimization steps. The purple/green solid line represents the average of the 25 curves for SPSA/QN-SPSA. The purple/green shaded area stands for the envelope of all 25 curves for SPSA/QN-SPSA.</p>
<p>The results are well aligned with the observations from Gacon et al. [1]. In this example with a rather simple energy landscape, the average behavior of SPSA matches the one from GD. QNG performs the best among the 4 candidates, however, requires the most circuit executions and shots per step. In particular for QPUs this is a severe disadvantage of this method. From the more shot-frugal options, QN-SPSA demonstrates the fastest convergence and best final accuracy, making it a promising candidate for variational algorithms.</p>
<p>From the step-wise optimization time, we can see the advantage of the stochastic optimizers (SPSA, QN-SPSA) over the analytical ones (GD, QNG). Note that this advantage will become more prominent with larger and more complicated circuits, as we will see in the next section when benchmarking with QAOA.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;GD takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;GD_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;QNG takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;QNG_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;QNSPSA takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;QNSPSA_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SPSA takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;SPSA_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GD takes 0.43 s per step
QNG takes 0.75 s per step
QNSPSA takes 0.20 s per step
SPSA takes 0.03 s per step
</pre></div>
</div>
</div>
</div>
</section>
<section id="benchmarking-with-qaoa">
<h2>Benchmarking with QAOA<a class="headerlink" href="#benchmarking-with-qaoa" title="Permalink to this heading">#</a></h2>
<p>As we know from the <a class="reference external" href="https://en.wikipedia.org/wiki/No_free_lunch_theorem">no-free-lunch theorem</a>, there is no universal optimizer that suits every problem. Lets take a look at the QN-SPSA optimizer in the context of QAOA problems, and analyze it’s performance for this important class of problems.</p>
<p>We now perform the benchmarking with QAOA on the four optimizers. To make sure that the results are reproducible, we can save a copy of the parameter initialization result with the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">params_init</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> 
   
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;source_scripts/qaoa_params_init_</span><span class="si">{</span><span class="n">n_qubits</span><span class="si">}</span><span class="s2">_qubits_</span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s2">_layers.npy&quot;</span><span class="p">,</span> 
    <span class="n">params_init</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As before, we provide you with the code to run this benchmark in the script <code class="docutils literal notranslate"><span class="pre">source_scripts/benchmark_qaoa_converge_speed</span></code>, so you can readily reproduce the results using Hybrid Jobs. The problem graph is defined with a node number of <code class="docutils literal notranslate"><span class="pre">n_qubits</span></code>, an edge number of <code class="docutils literal notranslate"><span class="pre">edges</span></code>, and a <code class="docutils literal notranslate"><span class="pre">seed</span></code> value. We have selected a fixed learning rate for each optimizer based on experience. In a real world experiment, you would fine tune each method during hyperparameter optimization, which goes beyond the scope of this example.  The following two cells take about 60 min to finish.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The execution time of the job is about 60 min, and charges about $0.25.</span>
<span class="c1"># Feel free to uncomment the cell to run.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">n_qubits = 10</span>
<span class="sd">optimizers = [&quot;GD&quot;, &quot;QNG&quot;, &quot;QNSPSA&quot;, &quot;SPSA&quot;]</span>
<span class="sd">repeats = [1, 1, 20, 20]</span>
<span class="sd">learn_rates = [1e-2, 5e-2, 0.1, 2e-2]</span>

<span class="sd">hyperparameters = {</span>
<span class="sd">    &quot;n_qubits&quot;: n_qubits,</span>
<span class="sd">    &quot;edges&quot;: 20,</span>
<span class="sd">    &quot;depth&quot;: 2,</span>
<span class="sd">    &quot;shots&quot;: 8192,</span>
<span class="sd">    &quot;seed&quot;: 198, # random seed for graph generation</span>
<span class="sd">    &quot;load_init_config&quot;: True,</span>
<span class="sd">    &quot;max_iter&quot;: 400,</span>
<span class="sd">}</span>

<span class="sd">max_iter = hyperparameters[&quot;max_iter&quot;]</span>

<span class="sd">jobs = []</span>
<span class="sd">for i in range(len(optimizers)):</span>
<span class="sd">    hyperparameters[&quot;spsa_repeats&quot;] = repeats[i]</span>
<span class="sd">    hyperparameters[&quot;optimizer&quot;] = optimizers[i]</span>
<span class="sd">    hyperparameters[&quot;learn_rate&quot;] = learn_rates[i]</span>

<span class="sd">    job_name = f&quot;qaoa-benchmark-qubit{n_qubits}-opt{optimizers[i]}&quot; + str(int(time.time()))</span>
<span class="sd">    instance_config = InstanceConfig(instanceType=&#39;ml.m5.large&#39;, volumeSizeInGb=30, instanceCount=1)</span>

<span class="sd">    job = AwsQuantumJob.create(</span>
<span class="sd">        device=&quot;local:pennylane/lightning.qubit&quot;,</span>
<span class="sd">        source_module=&quot;source_scripts&quot;,</span>
<span class="sd">        entry_point=&quot;source_scripts.benchmark_qaoa_converge_speed&quot;,</span>
<span class="sd">        job_name=job_name,</span>
<span class="sd">        hyperparameters=hyperparameters,</span>
<span class="sd">        instance_config=instance_config,</span>
<span class="sd">        image_uri=image_uri,</span>
<span class="sd">        wait_until_complete=False,</span>
<span class="sd">    )</span>
<span class="sd">    jobs.append(job)</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">job</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">job</span> <span class="ow">in</span> <span class="n">jobs</span><span class="p">]</span>
<span class="n">step</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)</span>
<span class="n">loss_gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;GD_loss_per_iter&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">loss_qng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;QNG_loss_per_iter&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">qnspsa_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;QNSPSA_loss_per_iter&#39;</span><span class="p">])</span>
<span class="n">qnspsa_loss_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">qnspsa_loss_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">qnspsa_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">qnspsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">spsa_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;SPSA_loss_per_iter&#39;</span><span class="p">])</span>
<span class="n">spsa_loss_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spsa_loss_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spsa_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">spsa_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">step</span><span class="p">,</span> <span class="n">loss_gd</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">,</span> <span class="n">loss_qng</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">,</span> <span class="n">qnspsa_loss_mean</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span>
    <span class="n">step</span><span class="p">,</span> <span class="n">spsa_loss_mean</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">qnspsa_loss_min</span><span class="p">,</span> <span class="n">qnspsa_loss_max</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.2</span><span class="p">)</span>
<span class="c1">#ax.fill_between(step, spsa_loss_min, spsa_loss_max, color=&#39;purple&#39;, alpha=.2)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;GD&#39;</span><span class="p">,</span> <span class="s1">&#39;QNG&#39;</span><span class="p">,</span> <span class="s1">&#39;QN-SPSA&#39;</span><span class="p">,</span> <span class="s1">&#39;SPSA&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Step&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/9f225d9e6d8aaee5cebad6076cac9676b94ee6fd5351b9393737ad58d352611c.png" src="../../../_images/9f225d9e6d8aaee5cebad6076cac9676b94ee6fd5351b9393737ad58d352611c.png" />
</div>
</div>
<p>GD, QNG and QN-SPSA are able to minimize the loss function to be below -13, giving an estimated ground state of -14 for the max cut problem compared to the true ground state energy of -16. As before, GD and QNG seem to outperform QN-SPSA when considering step-wise convergence. However, each step in GD and QNG require significantly more circuit executions compared to the stochastic QN-SPSA. Let’s have a closer look at that.</p>
<p>When we look at the time per step in our simulations, we can clearly see signals that GD and QNG are more expensive on a per-step basis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;GD takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;GD_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;QNG takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;QNG_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;QNSPSA takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;QNSPSA_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SPSA takes %.2f s per step&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s1">&#39;SPSA_duration&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">repeats</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">/</span> <span class="n">max_iter</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GD takes 4.05 s per step
QNG takes 4.73 s per step
QNSPSA takes 0.42 s per step
SPSA takes 0.19 s per step
</pre></div>
</div>
</div>
</div>
<p>The reason of the long optimization time per step for GD and QNG to optimize per step is in the gradient computation. The analytical optimizers (QNG, GD) compute gradients via the parameter shift rule, which requires executing 2$n_G$ circuits, where $n_G$ is the parameterized gate number. QAOA ansatz has only $2p$ parameters, but a rather large amount of parameterized gates. On the other hand, stochastic methods (QN-SPSA, SPSA) always execute a fixed number of circuits for each step, independent of the problem size.</p>
</section>
<section id="scaling-up-qn-spsa-on-larger-problems">
<h2>Scaling up: QN-SPSA on larger problems<a class="headerlink" href="#scaling-up-qn-spsa-on-larger-problems" title="Permalink to this heading">#</a></h2>
<p>The behavior and performance of different optimizers depend strongly on the problem instance and, in particular, the problem size.  As we have seen above, analytical gradient estimation, such as employed in GD and QNG quickly become impractical when the system size gets larger, due to the increasing number tasks and shots that are required to calculate the gradient. Stochastic optimizers, such as QN-SPSA are designed to overcome this challenge. Let’s take a look how QN-SPSA performs as we go to larger system sizes. In the following cells, we simulate a larger QAOA graph with 29 nodes and 58 edges. We use PennyLane’s GPU simulator <code class="docutils literal notranslate"><span class="pre">lightning.gpu</span></code> for this workload, as it provides up to 10X speedup for intermediate scale problems (problems with 20-29 qubits). Before you run the cell, note that QN-SPSA takes 3.5 min per step, and about 3.5 hours overall to finish the algorithm.</p>
<p><strong>Note:</strong> The following cell may be unable to complete with the default resource limits. You may contact <a class="reference external" href="https://support.console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase">AWS Support</a> to increase the limits on your account.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The execution time of the job is about 3.5 hours, and charges about $13.</span>
<span class="c1"># Feel free to uncomment the cell to run.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd"># select the PL_PYTORCH container, which supports lightning.gpu simulator</span>
<span class="sd">image_uri = retrieve_image(Framework.PL_PYTORCH, region_name)</span>
<span class="sd">n_qubits = 29</span>
<span class="sd">edges = 2 * n_qubits</span>
<span class="sd">hyperparameters = {</span>
<span class="sd">    &quot;n_qubits&quot;: n_qubits,</span>
<span class="sd">    &quot;edges&quot;: edges,</span>
<span class="sd">    &quot;depth&quot;: 2,</span>
<span class="sd">    &quot;shots&quot;: 8192,</span>
<span class="sd">    &quot;seed&quot;: 197,</span>
<span class="sd">    &quot;load_init_config&quot;: False,</span>
<span class="sd">    &quot;max_iter&quot;: 60,</span>
<span class="sd">    &quot;learn_rate&quot;: 1e-2,</span>
<span class="sd">}</span>
<span class="sd"># ml.p3.2xlarge provides a V100 GPU for the GPU simulator to run</span>
<span class="sd">instance_config = InstanceConfig(instanceType=&#39;ml.p3.2xlarge&#39;, volumeSizeInGb=30, instanceCount=1)</span>

<span class="sd">job_name = f&quot;qaoa-large-problem-gpu-qubits{n_qubits}-&quot; + str(int(time.time()))</span>


<span class="sd">job = AwsQuantumJob.create(</span>
<span class="sd">    device=&quot;local:pennylane/lightning.gpu&quot;,</span>
<span class="sd">    source_module=&quot;source_scripts&quot;,</span>
<span class="sd">    entry_point=&quot;source_scripts.qaoa_large_problem&quot;,</span>
<span class="sd">    job_name=job_name,</span>
<span class="sd">    hyperparameters=hyperparameters,</span>
<span class="sd">    instance_config=instance_config,</span>
<span class="sd">    image_uri=image_uri,</span>
<span class="sd">    wait_until_complete=False,</span>
<span class="sd">)</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the results:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
<span class="n">step</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>

<span class="n">loss_qnspsa</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;qnspsa_loss_per_iter&#39;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">loss_qnspsa</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;QN-SPSA&#39;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Step&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/e8cd2472419ba62c359a5a282bd3337d6e55409f77f9bfc51340bc689dfdf7a4.png" src="../../../_images/e8cd2472419ba62c359a5a282bd3337d6e55409f77f9bfc51340bc689dfdf7a4.png" />
</div>
</div>
<p>The QAOA algorithm provides a minimized loss value of -40. To further improve the QAOA solution from here, you can try to increase $p$ from 2 to a larger integer, or experiment with the other hyperparameters. As the simulator’s execution time scales roughly linearly with $p$, you should expect a longer run time.</p>
</section>
<section id="embedded-simulator-vs-on-demand-simulator">
<h2>Embedded simulator vs on-demand simulator<a class="headerlink" href="#embedded-simulator-vs-on-demand-simulator" title="Permalink to this heading">#</a></h2>
<p>As embedded simulators experience reduced latency, it enable us to run high-performant quantum circuit simulations. With PennyLane’s GPU simulator <code class="docutils literal notranslate"><span class="pre">lightning.gpu</span></code>, we are able to run simulation workloads up to 29 qubits, bottlenecked by the single-GPU memory. To go beyond 29 qubits, we can use the CPU simulator <code class="docutils literal notranslate"><span class="pre">lightning.qubit</span></code> on instances with sufficient memory and CPU power. For example, an <code class="docutils literal notranslate"><span class="pre">ml.m5.24xlarge</span></code> instance has 96 vCPUs and 384 GiB of memory, and it is able to simulate circuits up to 34-35 qubits.</p>
<p>On the other hand, On-demand simulators have the <a class="reference external" href="https://docs.aws.amazon.com/braket/latest/developerguide/braket-batching-tasks.html?tag=local002">task batching</a> feature to run circuit simulation tasks in parallel, which is integrated into PennyLane’s <code class="docutils literal notranslate"><span class="pre">qml.execute()</span></code> function. When the quantum algorithm can be efficiently parallelized, we would expect the on-demand simulators to provide a reasonable speedup.</p>
<p>Note that this speedup from task parallelization is algorithm specific. For QN-SPSA, we have written the optimizer class in a way it can best utilize the task batching. With the SV1 on-demand simulator, the same 29-node-graph QAOA problem has a step-wise optimization time of 3.5 min, similar to the result from the embedded simulator <code class="docutils literal notranslate"><span class="pre">lightning.gpu</span></code>.</p>
</section>
</section>
<section id="conclusion">
<h1>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h1>
<p>In this notebook, we demonstrate an example of using Braket Jobs and the embedded simulator feature to study a novel optimizer, QN-SPSA. With the example, we demonstrate how to use Hybrid Jobs to accelerate experimentation and research into varitational quantum algorithms, recommend a few best practices, and discuss the advantages and limitations of the embedded simulator.</p>
</section>
<section id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h1>
<p>[1] Gacon, J., Zoufal, C., Carleo, G., &amp; Woerner, S. (2021). <em>Simultaneous perturbation stochastic approximation of the quantum fisher information</em>. Quantum, 5, 567.</p>
<p>[2] Simultaneous perturbation stochastic approximation (2022). Wikipedia. https://en.wikipedia.org/wiki/Simultaneous_perturbation_stochastic_approximation</p>
<p>[3] Yamamoto, N. (2019). <em>On the natural gradient for variational quantum eigensolver</em>. arXiv preprint arXiv:1909.05074.</p>
<p>[4] Fubini–Study metric (2022). Wikipedia. https://en.wikipedia.org/wiki/Fubini%E2%80%93Study_metric</p>
<p>[5] Stokes, J., Izaac, J., Killoran, N., &amp; Carleo, G. (2020). <em>Quantum natural gradient</em>. Quantum, 4, 269.</p>
<p>[6] Farhi, E., Goldstone, J., &amp; Gutmann, S. (2014). <em>A quantum approximate optimization algorithm</em>. arXiv preprint arXiv:1411.4028.</p>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Benchmarking QN-SPSA optimizer with Amazon Braket Hybrid Jobs and embedded simulators</a><ul>
<li><a class="reference internal" href="#introduction-on-hybrid-jobs-and-embedded-simulators">Introduction on Hybrid Jobs and embedded simulators</a></li>
<li><a class="reference internal" href="#background">Background</a><ul>
<li><a class="reference internal" href="#variational-quantum-algorithms">Variational quantum algorithms</a></li>
<li><a class="reference internal" href="#qn-spsa-optimizer">QN-SPSA optimizer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#notebook-dependencies">Notebook dependencies</a></li>
<li><a class="reference internal" href="#implementation-and-notebook-test">Implementation and notebook test</a></li>
<li><a class="reference internal" href="#comparing-qn-spsa-with-other-optimizers">Comparing QN-SPSA with other optimizers</a></li>
<li><a class="reference internal" href="#benchmarking-with-qaoa">Benchmarking with QAOA</a></li>
<li><a class="reference internal" href="#scaling-up-qn-spsa-on-larger-problems">Scaling up: QN-SPSA on larger problems</a></li>
<li><a class="reference internal" href="#embedded-simulator-vs-on-demand-simulator">Embedded simulator vs on-demand simulator</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    </body>
</html>